import math
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
import requests
import streamlit as st

import folium
from streamlit_folium import st_folium
from populartimes import get as pt_get


# =========================
# 0. Session state
# =========================
if "results_ready" not in st.session_state:
    st.session_state["results_ready"] = False
if "df_pois" not in st.session_state:
    st.session_state["df_pois"] = None
if "df_all" not in st.session_state:
    st.session_state["df_all"] = None
if "zone_center" not in st.session_state:
    st.session_state["zone_center"] = None
if "picked_lat" not in st.session_state:
    st.session_state["picked_lat"] = None
if "picked_lon" not in st.session_state:
    st.session_state["picked_lon"] = None


# =========================
# 1. Utils g√©ographiques
# =========================

def geocode_address(address: str):
    """Retourne (lat, lon) √† partir d'une adresse avec Nominatim (OpenStreetMap)."""
    url = "https://nominatim.openstreetmap.org/search"
    params = {
        "q": address,
        "format": "json",
        "limit": 1
    }
    resp = requests.get(url, params=params, headers={"User-Agent": "streamlit-footfall-app"})
    resp.raise_for_status()
    data = resp.json()
    if not data:
        return None, None
    return float(data[0]["lat"]), float(data[0]["lon"])


def bbox_from_center(lat: float, lon: float, radius_m: int):
    """
    Calcule un rectangle englobant (bbox) autour d'un centre (lat, lon)
    √† partir d'un rayon en m√®tres.

    Retourne (southwest_lat, southwest_lon), (northeast_lat, northeast_lon)
    """
    # 1¬∞ de latitude ‚âà 111 km
    delta_lat = radius_m / 111_000.0

    # 1¬∞ de longitude ‚âà 111 km * cos(latitude)
    delta_lon = radius_m / (111_000.0 * math.cos(math.radians(lat)))

    sw = (lat - delta_lat, lon - delta_lon)
    ne = (lat + delta_lat, lon + delta_lon)
    return sw, ne


# =========================================
# 2. Fournisseur de donn√©es : Popular Times
# =========================================

GOOGLE_POI_TYPES = [
    "store",
    "shopping_mall",
    "supermarket",
    "grocery_or_supermarket",
    "department_store",
    "clothing_store",
    "bakery",
    "restaurant",
    "cafe",
    "bar",
    "movie_theater"
]


def fetch_places_populartimes(api_key: str, lat: float, lon: float, radius_m: int, max_pois: int):
    """
    Appelle Google Popular Times via la librairie `populartimes.get`
    en utilisant une bbox calcul√©e autour du centre.

    Retourne :
    - places : liste brute renvoy√©e par populartimes
    - df_pois : DataFrame des points d'int√©r√™t (un par √©tablissement)
    """
    sw, ne = bbox_from_center(lat, lon, radius_m)

    # La lib travaille sur une bbox (southwest, northeast)
    # southwest = (lat_min, lon_min), northeast = (lat_max, lon_max)
    sw_lat, sw_lon = sw
    ne_lat, ne_lon = ne

    # Appel √† PopularTimes
    places = pt_get(
        api_key,
        GOOGLE_POI_TYPES,
        (sw_lat, sw_lon),
        (ne_lat, ne_lon)
    )

    if not places:
        return [], pd.DataFrame()

    pois = []
    for p in places:
        coord = p.get("coordinates", {})
        pois.append({
            "place_id": p.get("id"),
            "name": p.get("name"),
            "types": ", ".join(p.get("types", [])),
            "lat": coord.get("lat"),
            "lon": coord.get("lng"),
        })

    df_pois = pd.DataFrame(pois).dropna(subset=["lat", "lon"])

    # On limite le nombre de POI
    if not df_pois.empty and len(df_pois) > max_pois:
        df_pois = df_pois.head(max_pois)

    # On filtre aussi la liste brute `places` pour ne garder que ceux des df_pois
    place_ids_kept = set(df_pois["place_id"].tolist())
    places_filtered = [p for p in places if p.get("id") in place_ids_kept]

    return places_filtered, df_pois


def build_daily_series_from_populartimes(place_data: dict, start_date, end_date):
    """
    Transforme le profil hebdomadaire PopularTimes en s√©rie journali√®re
    sur la p√©riode [start_date, end_date].

    PopularTimes renvoie, pour chaque jour de la semaine, 24 valeurs (0‚Äì100)
    => on agr√®ge par jour : somme des 24 heures = indice de flux quotidien.
    """
    rng = pd.date_range(start_date, end_date, freq="D")

    pop_week = place_data.get("populartimes", [])
    if not pop_week or len(pop_week) != 7:
        # Si donn√©es absentes, on renvoie une s√©rie √† 0
        return pd.DataFrame({
            "date": rng,
            "footfall": np.zeros(len(rng), dtype=float)
        })

    # pop_week est une liste de 7 dicts : [{"name": "Monday", "data": [...]}, ...]
    # On les range dans l'ordre Monday (0) ‚Üí Sunday (6)
    # En principe l'ordre est d√©j√† bon, mais on s√©curise
    day_name_to_index = {
        "Monday": 0,
        "Tuesday": 1,
        "Wednesday": 2,
        "Thursday": 3,
        "Friday": 4,
        "Saturday": 5,
        "Sunday": 6,
    }

    daily_pattern = [0.0] * 7
    for d in pop_week:
        name = d.get("name")
        data = d.get("data", [])
        if name in day_name_to_index and len(data) == 24:
            idx = day_name_to_index[name]
            # indice de flux quotidien = somme des 24 heures
            daily_pattern[idx] = float(sum(data))

    # Construction de la s√©rie
    values = []
    for d in rng:
        idx = d.weekday()  # Monday=0
        values.append(daily_pattern[idx])

    df = pd.DataFrame({"date": rng, "footfall": values})
    return df


# =========================
# 3. App Streamlit
# =========================

st.set_page_config(
    page_title="Analyse de flux - Popular Times",
    layout="wide"
)

st.title("üìà Analyse de flux de personnes par zone ‚Äì donn√©es Google Popular Times")

st.write(
    """
Cette application estime la **fr√©quentation quotidienne** d'une zone en s'appuyant sur :

- les √©tablissements pr√©sents autour d'un point (donn√©es Google Maps),
- leurs profils d'**affluence moyenne horaire** (*Popular Times*),
- une agr√©gation en **indice de flux quotidien** sur la p√©riode choisie.

üîç **Important** : Popular Times ne fournit pas un historique jour par jour,
mais un **profil moyen par jour de semaine**.  
La s√©rie produite ici est donc un **profil moyen journalier r√©p√©t√© sur la p√©riode**,
et non la r√©alit√© exacte de chaque date.
"""
)

# ---- Cl√© API Google ----
st.sidebar.header("üîë Connexion Google")
google_api_key = st.sidebar.text_input(
    "Cl√© API Google Maps / Places (obligatoire)",
    type="password",
    help="Cl√© li√©e √† un projet Google Cloud avec acc√®s √† l'API Places."
)

# ---- Param√®tres de la zone ----
st.sidebar.header("üó∫Ô∏è Param√®tres de la zone")

mode = st.sidebar.radio(
    "Mode de s√©lection de la zone",
    ["Carte (clic)", "Adresse", "Latitude / Longitude"],
    index=0
)

# Raccourci villes bretonnes (pour aider en mode Adresse)
bzh_choice = None
if mode == "Adresse":
    bzh_choice = st.sidebar.selectbox(
        "Raccourci villes bretonnes",
        ["(aucune)", "Rennes", "Brest", "Quimper", "Lorient", "Vannes", "Saint-Brieuc"]
    )

# P√©riode d'analyse
today = datetime.today().date()
default_start = today - timedelta(days=90)
start_date = st.sidebar.date_input("Date de d√©but", default_start)
end_date = st.sidebar.date_input("Date de fin", today)

if start_date > end_date:
    st.sidebar.error("La date de d√©but doit √™tre <= √† la date de fin.")

radius_m = st.sidebar.slider("Rayon de recherche (m√®tres)", min_value=200, max_value=3000, value=800, step=100)
max_pois = st.sidebar.slider("Nombre maximum de POI √† analyser", 3, 30, 10)

run_button = st.sidebar.button("üöÄ Lancer / mettre √† jour l'analyse")

# =========================
# 4. Carte interactive (mode Carte)
# =========================

if mode == "Carte (clic)":
    st.subheader("üó∫Ô∏è S√©lectionne un point sur la carte (clic gauche)")
    # Carte centr√©e sur la Bretagne
    center_bzh = [48.0, -2.8]
    m = folium.Map(location=center_bzh, zoom_start=7)

    # Si un point a d√©j√† √©t√© choisi, on l'affiche
    if st.session_state["picked_lat"] is not None and st.session_state["picked_lon"] is not None:
        folium.Marker(
            [st.session_state["picked_lat"], st.session_state["picked_lon"]],
            tooltip="Point s√©lectionn√©",
            icon=folium.Icon(color="red")
        ).add_to(m)

    map_data = st_folium(m, height=450, width=900, key="bzh_map")

    # Gestion du clic sur la carte
    if map_data and map_data.get("last_clicked"):
        clicked_lat = map_data["last_clicked"]["lat"]
        clicked_lon = map_data["last_clicked"]["lng"]
        st.session_state["picked_lat"] = clicked_lat
        st.session_state["picked_lon"] = clicked_lon

    if st.session_state["picked_lat"] is not None:
        st.info(
            f"Point s√©lectionn√© : lat = {st.session_state['picked_lat']:.5f}, "
            f"lon = {st.session_state['picked_lon']:.5f}"
        )

# =========================
# 5. Lancement / mise √† jour de l'analyse
# =========================

if run_button and start_date <= end_date:
    if not google_api_key:
        st.error("Merci de renseigner une cl√© API Google valide dans la barre lat√©rale.")
        st.stop()

    # D√©termination du centre de zone
    if mode == "Carte (clic)":
        if st.session_state["picked_lat"] is None or st.session_state["picked_lon"] is None:
            st.error("Clique d'abord sur la carte pour choisir un point.")
            st.stop()
        lat = st.session_state["picked_lat"]
        lon = st.session_state["picked_lon"]

    elif mode == "Adresse":
        if bzh_choice and bzh_choice != "(aucune)":
            default_address = f"{bzh_choice}, Bretagne, France"
        else:
            default_address = "Rennes, France"
        address = st.sidebar.text_input("Adresse / ville / lieu", default_address, key="addr_input_run")
        addr_to_geocode = address or default_address

        with st.spinner("G√©ocodage de l'adresse‚Ä¶"):
            lat, lon = geocode_address(addr_to_geocode)
            if lat is None:
                st.error("Impossible de g√©ocoder cette adresse. Essaie d'√™tre plus pr√©cis.")
                st.stop()

    else:  # Latitude / Longitude
        lat = st.sidebar.number_input("Latitude", value=48.1173, format="%.6f", key="lat_run")
        lon = st.sidebar.number_input("Longitude", value=-1.6778, format="%.6f", key="lon_run")

    st.session_state["zone_center"] = (lat, lon)

    # 1) R√©cup√©ration des lieux + Popular Times
    with st.spinner("R√©cup√©ration des √©tablissements et de leurs profils Popular Times‚Ä¶"):
        try:
            places, df_pois = fetch_places_populartimes(
                google_api_key,
                lat,
                lon,
                radius_m=radius_m,
                max_pois=max_pois
            )
        except Exception as e:
            st.error(f"Erreur lors de l'appel Popular Times : {e}")
            st.session_state["results_ready"] = False
            st.stop()

    if df_pois.empty:
        st.warning("Aucun √©tablissement avec donn√©es Popular Times trouv√© dans ce rayon.")
        st.session_state["results_ready"] = False
    else:
        # 2) Construction des s√©ries journali√®res pour chaque √©tablissement
        all_series = []
        progress = st.progress(0)
        total = len(places)

        places_by_id = {p.get("id"): p for p in places}

        for i, (_, poi) in enumerate(df_pois.iterrows(), start=1):
            place_id = poi["place_id"]
            pdata = places_by_id.get(place_id)
            if not pdata:
                continue

            df_ts = build_daily_series_from_populartimes(pdata, start_date, end_date)
            df_ts["poi_name"] = poi["name"]
            df_ts["poi_type"] = poi["types"]
            df_ts["place_id"] = place_id
            all_series.append(df_ts)

            progress.progress(i / total)

        if not all_series:
            st.warning("Impossible de construire des s√©ries √† partir des donn√©es Popular Times disponibles.")
            st.session_state["results_ready"] = False
        else:
            df_all = pd.concat(all_series, ignore_index=True)

            # Stockage en session_state
            st.session_state["df_pois"] = df_pois
            st.session_state["df_all"] = df_all
            st.session_state["results_ready"] = True


# =========================
# 6. Affichage des r√©sultats
# =========================

if st.session_state["results_ready"] and st.session_state["df_pois"] is not None:
    df_pois = st.session_state["df_pois"]
    df_all = st.session_state["df_all"]
    lat, lon = st.session_state["zone_center"]

    st.success(f"Zone analys√©e centr√©e sur lat = {lat:.5f}, lon = {lon:.5f}")

    st.subheader("üìç √âtablissements pris en compte (Google Places)")
    st.dataframe(df_pois[["name", "types", "lat", "lon"]])

    # Carte des POI
    st.markdown("### üó∫Ô∏è Carte des √©tablissements de la zone")
    df_map = df_pois.rename(columns={"lat": "latitude", "lon": "longitude"})
    st.map(df_map, zoom=13)

    st.subheader("üìä S√©ries journali√®res (indice de flux)")

    tab1, tab2 = st.tabs(["D√©tail par √©tablissement", "Moyenne de la zone"])

    with tab1:
        st.markdown("### üìå D√©tail par √©tablissement (indice bas√© sur Popular Times)")
        poi_selected = st.selectbox("Choisir un √©tablissement", df_pois["name"].tolist())
        df_one = df_all[df_all["poi_name"] == poi_selected].copy()
        df_one = df_one.sort_values("date")

        st.line_chart(
            df_one.set_index("date")["footfall"],
            height=300
        )
        st.write(df_one[["date", "footfall"]])

    with tab2:
        st.markdown("### üìä Moyenne journali√®re de l'indice de flux sur l'ensemble de la zone")

        df_zone = (
            df_all
            .groupby("date", as_index=False)["footfall"]
            .mean()
            .rename(columns={"footfall": "footfall_mean"})
        )

        df_zone = df_zone.sort_values("date")

        # Courbe de moyenne
        st.line_chart(
            df_zone.set_index("date")["footfall_mean"],
            height=300
        )
        st.write(df_zone)

        # üîπ Pr√©ambule sur l'origine et la nature de la donn√©e
        st.markdown(
            """
            ### ‚ÑπÔ∏è Origine et nature de l'indicateur

            - **Origine** : donn√©es issues de Google Maps / Popular Times, via un appel API sur les
              √©tablissements pr√©sents dans le p√©rim√®tre √©tudi√©.
            - **Ce que compte l'indicateur** :
              - pour chaque √©tablissement, Popular Times fournit un **profil horaire moyen** (0‚Äì100)
                par jour de la semaine ;
              - ces profils sont **agr√©g√©s par jour** (somme des 24 heures) pour produire un
                **indice quotidien de fr√©quentation** ;
              - pour la zone, on fait ensuite une **moyenne** de ces indices sur
                l'ensemble des √©tablissements retenus.
            - **Granularit√©** :
              - 1 point = 1 jour civil,
              - la s√©rie est un **profil moyen r√©p√©t√©** sur la p√©riode, pas un historique r√©el date par date.
            """
        )

        # üîπ Bloc statistique de synth√®se
        st.markdown("### üìå Statistiques de synth√®se sur la p√©riode")

        if len(df_zone) >= 2:
            start_date_series = df_zone["date"].iloc[0]
            end_date_series = df_zone["date"].iloc[-1]
            start_val = float(df_zone["footfall_mean"].iloc[0])
            end_val = float(df_zone["footfall_mean"].iloc[-1])
            avg_val = float(df_zone["footfall_mean"].mean())
            total_flux = float(df_zone["footfall_mean"].sum())
            n_days = int(len(df_zone))

            growth_abs = end_val - start_val
            if start_val > 0:
                growth_pct = (end_val / start_val - 1) * 100
            else:
                growth_pct = None

            col1, col2, col3 = st.columns(3)

            col1.metric(
                "Indice moyen quotidien de flux",
                f"{avg_val:,.0f}",
                help="Moyenne de l'indice quotidien de fr√©quentation (Popular Times agr√©g√©) sur la p√©riode."
            )

            col2.metric(
                "Indice cumul√© de flux sur la p√©riode",
                f"{total_flux:,.0f}",
                help="Somme des indices quotidiens de fr√©quentation (profil moyen r√©p√©t√©)."
            )

            if growth_pct is not None:
                col3.metric(
                    "Croissance apparente sur la p√©riode",
                    f"{growth_pct:,.1f} %",
                    delta=f"{growth_abs:,.0f}",
                    help=(
                        "Variation entre le premier et le dernier jour de la p√©riode, "
                        "en % et en niveau absolu, sur la base du profil moyen."
                    )
                )
            else:
                col3.metric(
                    "Croissance sur la p√©riode",
                    "n.c.",
                    help="Non calculable car la valeur de d√©part est nulle ou manquante."
                )

            st.caption(
                f"P√©riode analys√©e : du {start_date_series.date()} au {end_date_series.date()} "
                f"({n_days} jours)."
            )
        else:
            st.info("La p√©riode s√©lectionn√©e est trop courte pour calculer une croissance (au moins 2 jours n√©cessaires).")

        # Export CSV
        csv = df_zone.to_csv(index=False).encode("utf-8")
        st.download_button(
            "üíæ T√©l√©charger la s√©rie moyenne journali√®re (CSV)",
            data=csv,
            file_name="footfall_zone_daily_mean_populartimes.csv",
            mime="text/csv"
        )
else:
    st.info("Configure la zone + la cl√© API dans la barre lat√©rale puis clique sur **üöÄ Lancer / mettre √† jour l'analyse**.")
